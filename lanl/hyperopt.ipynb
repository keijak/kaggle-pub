{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "data_dir = Path.home() / 'Desktop/kaggle/data/lanl'\n",
    "os.environ['DATA_DIR'] = str(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from tensorflow import keras\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "import optuna\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6.0G\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K May 31 20:54 CatBoost_2019-05-31_test_2.055_train_1.806.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  76K Jun  1 01:18 CatBoost_2019-06-01_test_1.848_train_1.534.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 02:53 CatBoost_2019-06-01_test_1.982_train_1.671.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 15:41 CatBoost_2019-06-01_test_2.008_train_1.667.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 17:34 CatBoost_2019-06-01_test_2.105_train_1.810.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:29 CatBoost_2019-06-01_test_2.108_train_1.763.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:08 CatBoost_2019-06-01_test_2.112_train_1.830.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 21:12 CatBoost_2019-06-01_test_2.113_train_1.814.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 21:39 CatBoost_2019-06-01_test_2.147_train_1.815.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 22:20 CatBoost_2019-06-01_test_2.156_train_1.743.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  2 14:30 CatBoost_2019-06-02_test_2.220_train_1.839.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  2 14:40 CatBoost_2019-06-02_test_2.220_train_1.848.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup 3.6G Feb  8 21:07 df_train.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 7.7M Jun  1 17:25 df_xtest_extra_v3.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 5.6M Jun  2 12:28 df_xtest_extra_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 629K Jun  1 02:03 df_xtest_v2.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup 629K Jun  1 02:21 df_xtest_v2.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 7.7M Jun  1 12:09 df_xtest_v3.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 5.6M Jun  2 11:00 df_xtest_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  36M Jun  2 12:48 df_xtrain_classified_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  16M Jun  1 17:25 df_xtrain_extra_stride0.8_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  36M Jun  2 12:28 df_xtrain_extra_stride4_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  16M Jun  1 15:20 df_xtrain_extra_stride75_v3.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  36M Jun  2 12:47 df_xtrain_filtered_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 3.8M Jun  1 02:21 df_xtrain_oof_v2.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  36M Jun  2 10:35 df_xtrain_stride4_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  16M Jun  1 11:42 df_xtrain_stride75_v3.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 3.6M Jun  1 02:02 df_xtrain_strides4_v2.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 261K Jun  2 10:35 df_ytrain_stride4_v4.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  82K Jun  1 11:42 df_ytrain_stride75_v3.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup 263K Jun  1 02:02 df_ytrain_strides4_v2.pickle\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:46 Keras_2019-06-01_test_2.079_train_2.086.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 21:20 Keras_2019-06-01_test_2.102_train_2.155.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 22:26 Keras_2019-06-01_test_2.110_train_2.181.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 21:47 Keras_2019-06-01_test_2.122_train_2.181.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  2 14:30 Keras_2019-06-02_test_2.220_train_nan.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  2 14:47 Keras_2019-06-02_test_3.095_train_5.911.csv\r\n",
      "drwxr-x--- 2 maekawa primarygroup 4.0K Jun  2 14:45 keras_logs\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:31 lanl_submission_ensemble1.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:47 lanl_submission_ensemble2.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  1 19:22 lanl_submission_genetic_programming.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  53K Jun  1 19:22 lanl_submission_rnn_starter.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  75K Jun  2 20:34 LightGBM_2019-06-02_test_2.336_train_1.960.csv\r\n",
      "-rw-r----- 1 maekawa primarygroup  34K Feb  8 20:51 sample_submission.csv\r\n",
      "drwxr-x--- 2 maekawa primarygroup  88K Apr  5 21:00 testdata\r\n",
      "-rw-r----- 1 maekawa primarygroup 242M Feb  8 20:51 test.zip\r\n",
      "-rw-r----- 1 maekawa primarygroup 2.1G Feb  8 20:51 train.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(data_dir / 'df_xtrain_classified_v4.pickle')\n",
    "y_train = pd.read_pickle(data_dir / 'df_ytrain_stride4_v4.pickle')\n",
    "X_test = pd.read_pickle(data_dir / 'df_xtest_v4.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (16626, 278) y: (16626, 2) Test X: (2624, 276)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X: {} y: {} Test X: {}\".format(X_train.shape, y_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['oof_pred'] = X_train.oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sort_values(by='oof_pred', ascending=False, inplace=True)\n",
    "y_train.sort_values(by='oof_pred', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6602e88860>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.oof_pred.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7000\n",
    "X_train = X_train.iloc[:N]\n",
    "y_train = y_train.iloc[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f65e54948d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.oof_pred.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sort_index(inplace=True)\n",
    "y_train.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['oof_pred']\n",
    "del X_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 276)\n",
      "(2624, 276)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminators_top250 = [\n",
    "    'time_from_prev_failure',\n",
    "    'fftr_max',\n",
    "    'fftr_abs_max',\n",
    "] + [\n",
    "    'ffti_Moving_average_6000_mean',\n",
    "    'ffti_abs_q01',\n",
    "    'ffti_av_change_abs_roll_std_10',\n",
    "    'ffti_av_change_abs_roll_std_100',\n",
    "    'ffti_av_change_abs_roll_std_1000',\n",
    "    'ffti_classic_sta_lta3_mean',\n",
    "    'ffti_mean_change_abs',\n",
    "    'ffti_min_roll_std_10',\n",
    "    'ffti_min_roll_std_100',\n",
    "    'ffti_min_roll_std_1000',\n",
    "    'ffti_q01_roll_std_100',\n",
    "    'ffti_q05_roll_std_10',\n",
    "    'ffti_q05_roll_std_1000',\n",
    "    'fftr_abs_min',\n",
    "    'fftr_abs_q01',\n",
    "    'fftr_max_roll_mean_10',\n",
    "    'fftr_max_roll_mean_100',\n",
    "    'fftr_max_to_min_diff',\n",
    "    'fftr_mean_change_abs',\n",
    "    'fftr_min_roll_std_10',\n",
    "    'fftr_min_roll_std_100',\n",
    "    'fftr_q01_roll_std_10',\n",
    "    'fftr_q01_roll_std_100',\n",
    "    'fftr_q05_roll_std_10',\n",
    "    'fftr_q95_roll_mean_1000',\n",
    "    'x_abs_trend',\n",
    "    'x_av_change_abs_roll_mean_10',\n",
    "    'x_av_change_abs_roll_mean_100',\n",
    "    'x_av_change_abs_roll_std_10',\n",
    "    'x_av_change_abs_roll_std_100',\n",
    "    'x_av_change_abs_roll_std_1000',\n",
    "    'x_avg_first_10000',\n",
    "    'x_avg_first_50000',\n",
    "    'x_avg_last_10000',\n",
    "    'x_classic_sta_lta2_mean',\n",
    "    'x_classic_sta_lta4_mean',\n",
    "    'x_max_first_50000',\n",
    "    'x_max_roll_mean_1000',\n",
    "    'x_max_to_min',\n",
    "    'x_max_to_min_diff',\n",
    "    'x_min_roll_mean_1000',\n",
    "    'x_min_roll_std_10',\n",
    "    'x_min_roll_std_100',\n",
    "    'x_q01_roll_mean_100',\n",
    "    'x_q05_roll_mean_100',\n",
    "    'x_q05_roll_mean_1000',\n",
    "    'x_q05_roll_std_10',\n",
    "    'x_q95_roll_mean_1000',\n",
    "    'x_q99_roll_mean_1000',\n",
    "    'x_skew',\n",
    "] + [\n",
    "    'fftr_abs_max_roll_mean_10',\n",
    "    'ffti_q01_roll_std_10',\n",
    "    'fftr_abs_max_roll_mean_100',\n",
    "    'fftr_min_roll_std_1000',\n",
    "    'x_q01_roll_mean_1000',\n",
    "    'ffti_skew',\n",
    "    'fftr_med',\n",
    "    'ffti_mean',\n",
    "    'x_q05_roll_std_100',\n",
    "    'x_min_roll_mean_100',\n",
    "    'fftr_av_change_abs_roll_std_10',\n",
    "    'fftr_q05_roll_mean_1000',\n",
    "    'fftr_av_change_abs_roll_mean_10',\n",
    "    'x_avg_last_50000',\n",
    "    'x_abs_max_roll_mean_1000',\n",
    "    'ffti_q05_roll_std_100',\n",
    "    'ffti_avg_first_10000',\n",
    "    'x_q05_roll_std_1000',\n",
    "    'ffti_ave10',\n",
    "    'x_std_roll_mean_1000',\n",
    "    'x_classic_sta_lta1_mean',\n",
    "    'ffti_med',\n",
    "    'fftr_av_change_abs_roll_mean_1000',\n",
    "    'x_std_first_10000',\n",
    "    'ffti_q01_roll_std_1000',\n",
    "    'ffti_trend',\n",
    "    'x_q95_roll_mean_100',\n",
    "    'x_min_first_50000',\n",
    "    'fftr_max_roll_mean_1000',\n",
    "    'x_min_roll_std_1000',\n",
    "    'ffti_abs_q05',\n",
    "    'fftr_q01_roll_std_1000',\n",
    "    'ffti_kurt',\n",
    "    'x_av_change_abs_roll_mean_1000',\n",
    "    'fftr_ave10',\n",
    "    'x_classic_sta_lta3_mean',\n",
    "    'fftr_q05_roll_std_100',\n",
    "    'ffti_Hann_window_mean',\n",
    "    'fftr_min_roll_mean_1000',\n",
    "    'fftr_av_change_abs_roll_std_1000',\n",
    "    'x_q01_roll_std_10',\n",
    "    'x_q01_roll_std_1000',\n",
    "    'fftr_avg_first_10000',\n",
    "    'fftr_q99_roll_mean_1000',\n",
    "    'x_max_first_10000',\n",
    "    'ffti_ave_roll_mean_10',\n",
    "    'x_ave10',\n",
    "    'ffti_Moving_average_1500_mean',\n",
    "    'ffti_avg_first_50000',\n",
    "    'ffti_Moving_average_3000_mean',\n",
    "] + [\n",
    "    'x_exp_Moving_average_30000_mean',\n",
    "    'fftr_av_change_abs_roll_std_100',\n",
    "    'fftr_abs_trend',\n",
    "    'ffti_sum',\n",
    "    'fftr_abs_max_roll_mean_1000',\n",
    "    'ffti_avg_last_50000',\n",
    "    'ffti_avg_last_10000',\n",
    "    'fftr_av_change_abs_roll_mean_100',\n",
    "    'fftr_avg_last_10000',\n",
    "    'x_Moving_average_3000_mean',\n",
    "    'x_min_first_10000',\n",
    "    'fftr_q95_roll_mean_100',\n",
    "    'x_exp_Moving_average_3000_mean',\n",
    "    'fftr_q01_roll_mean_1000',\n",
    "    'x_q05_roll_mean_10',\n",
    "    'fftr_max_roll_std_1000',\n",
    "    'ffti_av_change_abs_roll_mean_10',\n",
    "    'fftr_Moving_average_6000_mean',\n",
    "    'fftr_max_roll_std_10',\n",
    "    'x_q01_roll_std_100',\n",
    "    'x_q99_roll_mean_100',\n",
    "    'fftr_q05_roll_std_1000',\n",
    "    'fftr_avg_last_50000',\n",
    "    'x_trend',\n",
    "    'x_min_last_10000',\n",
    "    'fftr_max_to_min',\n",
    "    'x_std_first_50000',\n",
    "    'ffti_ave_roll_mean_100',\n",
    "    'x_exp_Moving_average_300_mean',\n",
    "    'ffti_max_roll_std_1000',\n",
    "    'fftr_trend',\n",
    "    'fftr_exp_Moving_average_30000_mean',\n",
    "    'x_max_last_10000',\n",
    "    'x_max_last_50000',\n",
    "    'x_std_last_10000',\n",
    "    'x_iqr',\n",
    "    'x_Moving_average_6000_mean',\n",
    "    'ffti_exp_Moving_average_300_mean',\n",
    "    'ffti_Moving_average_700_mean',\n",
    "    'ffti_q05_roll_mean_1000',\n",
    "    'ffti_exp_Moving_average_3000_mean',\n",
    "    'fftr_abs_q05',\n",
    "    'x_max',\n",
    "    'fftr_classic_sta_lta3_mean',\n",
    "    'ffti_count_big',\n",
    "    'x_q95_roll_std_1000',\n",
    "    'fftr_exp_Moving_average_3000_mean',\n",
    "    'x_Moving_average_1500_mean',\n",
    "    'x_q95_roll_std_10',\n",
    "    'x_min_last_50000',\n",
    "] + [\n",
    "    'fftr_abs_max_roll_std_10',\n",
    "    'x_mean',\n",
    "    'x_Moving_average_700_mean',\n",
    "    'fftr_std_roll_mean_1000',\n",
    "    'x_ave_roll_mean_1000',\n",
    "    'fftr_max_roll_std_100',\n",
    "    'ffti_av_change_abs_roll_mean_100',\n",
    "    'ffti_q95_roll_mean_1000',\n",
    "    'fftr_exp_Moving_average_300_mean',\n",
    "    'ffti_exp_Moving_average_30000_mean',\n",
    "    'x_std_last_50000',\n",
    "    'fftr_q01_roll_mean_100',\n",
    "    'fftr_avg_first_50000',\n",
    "    'x_q99_roll_std_1000',\n",
    "    'x_Hann_window_mean',\n",
    "    'x_mean_change_abs',\n",
    "    'x_min_roll_mean_10',\n",
    "    'fftr_q99_roll_mean_100',\n",
    "    'x_kurt',\n",
    "    'fftr_min',\n",
    "    'ffti_max_roll_std_10',\n",
    "    'x_max_roll_mean_100',\n",
    "    'fftr_std_first_10000',\n",
    "    'ffti_std_roll_mean_1000',\n",
    "    'ffti_iqr',\n",
    "    'ffti_ave_roll_mean_1000',\n",
    "    'x_std_roll_mean_100',\n",
    "    'fftr_Moving_average_3000_mean',\n",
    "    'fftr_q05_roll_mean_100',\n",
    "    'fftr_abs_max_roll_std_1000',\n",
    "    'fftr_min_roll_mean_100',\n",
    "    'x_min',\n",
    "    'fftr_min_roll_mean_10',\n",
    "    'x_q95_roll_std_100',\n",
    "    'ffti_av_change_abs_roll_mean_1000',\n",
    "    'ffti_max_to_min_diff',\n",
    "    'fftr_max_last_50000',\n",
    "    'ffti_max_roll_mean_1000',\n",
    "    'x_max_roll_mean_10',\n",
    "    'x_max_roll_std_10',\n",
    "    'ffti_std_roll_mean_100',\n",
    "    'x_q95_roll_mean_10',\n",
    "    'ffti_q01_roll_mean_1000',\n",
    "    'x_max_roll_std_100',\n",
    "    'fftr_q95_roll_std_100',\n",
    "    'ffti_min_first_50000',\n",
    "    'ffti_max_roll_mean_100',\n",
    "    'ffti_max_roll_mean_10',\n",
    "    'ffti_q05_roll_mean_100',\n",
    "    'x_MA_400MA_BB_low_mean'\n",
    "] + [\n",
    "    'x_sum',\n",
    "    'fftr_abs_max_roll_std_100',\n",
    "    'x_abs_max',\n",
    "    'x_abs_max_roll_std_10',\n",
    "    'x_ave_roll_mean_100',\n",
    "    'x_ave_roll_mean_10',\n",
    "    'x_abs_max_roll_mean_100',\n",
    "    'ffti_q99_roll_mean_1000',\n",
    "    'ffti_abs_max_roll_std_10',\n",
    "    'fftr_min_first_50000',\n",
    "    'x_q001',\n",
    "    'ffti_min_roll_mean_10',\n",
    "    'fftr_max_last_10000',\n",
    "    'ffti_min_roll_mean_1000',\n",
    "    'x_abs_max_roll_mean_10',\n",
    "    'ffti_min_roll_mean_100',\n",
    "    'fftr_std_roll_mean_100',\n",
    "    'ffti_q95',\n",
    "    'ffti_abs_max_roll_std_1000',\n",
    "    'fftr_iqr',\n",
    "    'ffti_q95_roll_mean_100',\n",
    "    'fftr_Moving_average_700_mean',\n",
    "    'fftr_count_big',\n",
    "    'fftr_q95',\n",
    "    'x_max_roll_std_1000',\n",
    "    'x_abs_max_roll_std_100',\n",
    "    'fftr_q999',\n",
    "    'ffti_abs_max_roll_mean_1000',\n",
    "    'fftr_ave_roll_mean_1000',\n",
    "    'ffti_q01_roll_mean_100',\n",
    "    'fftr_Hann_window_mean',\n",
    "    'x_MA_700MA_BB_low_mean',\n",
    "    'x_q01_roll_mean_10',\n",
    "    'x_Hilbert_mean',\n",
    "    'fftr_q95_roll_std_10',\n",
    "    'fftr_ave_roll_mean_10',\n",
    "    'fftr_Moving_average_1500_mean',\n",
    "    'ffti_q95_roll_std_100',\n",
    "    'ffti_max_roll_std_100',\n",
    "    'fftr_classic_sta_lta4_mean',\n",
    "    'fftr_q05_roll_mean_10',\n",
    "    'fftr_q01_roll_mean_10',\n",
    "    'fftr_q95_roll_mean_10',\n",
    "    'ffti_abs_max_roll_mean_100',\n",
    "    'x_q999',\n",
    "    'x_q99_roll_mean_10',\n",
    "    'fftr_q95_roll_std_1000',\n",
    "    'fftr_min_first_10000',\n",
    "    'ffti_q05_roll_mean_10',\n",
    "    'ffti_min_last_50000'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = list(X_train.columns)\n",
    "\n",
    "for f in discriminators_top250:\n",
    "    if f in train_columns:\n",
    "        train_columns.remove(f)\n",
    "\n",
    "len(train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_label = y_train.time_to_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import gc\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "#optional but advised\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#GLOBAL HYPEROPT PARAMETERS\n",
    "NUM_EVALS = 1000 #number of hyperopt evaluation rounds\n",
    "N_FOLDS = 5 #number of cross-validation folds on data in each evaluation round\n",
    "\n",
    "#LIGHTGBM PARAMETERS\n",
    "LGBM_MAX_LEAVES = 2**11 #maximum number of leaves per tree for LightGBM\n",
    "LGBM_MAX_DEPTH = 25 #maximum tree depth for LightGBM\n",
    "EVAL_METRIC_LGBM_REG = 'mae' #LightGBM regression metric. Note that 'rmse' is more commonly used \n",
    "EVAL_METRIC_LGBM_CLASS = 'auc'#LightGBM classification metric\n",
    "\n",
    "#XGBOOST PARAMETERS\n",
    "XGB_MAX_LEAVES = 2**12 #maximum number of leaves when using histogram splitting\n",
    "XGB_MAX_DEPTH = 25 #maximum tree depth for XGBoost\n",
    "EVAL_METRIC_XGB_REG = 'mae' #XGBoost regression metric\n",
    "EVAL_METRIC_XGB_CLASS = 'auc' #XGBoost classification metric\n",
    "\n",
    "#CATBOOST PARAMETERS\n",
    "CB_MAX_DEPTH = 8 #maximum tree depth in CatBoost\n",
    "OBJECTIVE_CB_REG = 'MAE' #CatBoost regression metric\n",
    "OBJECTIVE_CB_CLASS = 'Logloss' #CatBoost classification metric\n",
    "\n",
    "#OPTIONAL OUTPUT\n",
    "BEST_SCORE = 0\n",
    "\n",
    "def quick_hyperopt(data, labels, package='lgbm', num_evals=NUM_EVALS, diagnostic=False):\n",
    "    \n",
    "    #==========\n",
    "    #LightGBM\n",
    "    #==========\n",
    "    \n",
    "    if package=='lgbm':\n",
    "        \n",
    "        print('Running {} rounds of LightGBM parameter optimisation:'.format(num_evals))\n",
    "        #clear space\n",
    "        gc.collect()\n",
    "        \n",
    "        integer_params = ['max_depth',\n",
    "                         'num_leaves',\n",
    "                          'max_bin',\n",
    "                         'min_data_in_leaf',\n",
    "                         'min_data_in_bin']\n",
    "        \n",
    "        def objective(space_params):\n",
    "            \n",
    "            #cast integer params from float to int\n",
    "            for param in integer_params:\n",
    "                space_params[param] = int(space_params[param])\n",
    "            \n",
    "            #extract nested conditional parameters\n",
    "            if space_params['boosting']['boosting'] == 'goss':\n",
    "                top_rate = space_params['boosting'].get('top_rate')\n",
    "                other_rate = space_params['boosting'].get('other_rate')\n",
    "                #0 <= top_rate + other_rate <= 1\n",
    "                top_rate = max(top_rate, 0)\n",
    "                top_rate = min(top_rate, 0.5)\n",
    "                other_rate = max(other_rate, 0)\n",
    "                other_rate = min(other_rate, 0.5)\n",
    "                space_params['top_rate'] = top_rate\n",
    "                space_params['other_rate'] = other_rate\n",
    "            \n",
    "            subsample = space_params['boosting'].get('subsample', 1.0)\n",
    "            space_params['boosting'] = space_params['boosting']['boosting']\n",
    "            space_params['subsample'] = subsample\n",
    "            \n",
    "            #for classification, set stratified=True and metrics=EVAL_METRIC_LGBM_CLASS\n",
    "            cv_results = lgb.cv(space_params, train, nfold = N_FOLDS, stratified=False,\n",
    "                                early_stopping_rounds=100, metrics=EVAL_METRIC_LGBM_REG, seed=42)\n",
    "            \n",
    "            best_loss = cv_results['l1-mean'][-1] #'l2-mean' for rmse\n",
    "            #for classification, comment out the line above and uncomment the line below:\n",
    "            #best_loss = 1 - cv_results['auc-mean'][-1]\n",
    "            #if necessary, replace 'auc-mean' with '[your-preferred-metric]-mean'\n",
    "            return{'loss':best_loss, 'status': STATUS_OK }\n",
    "        \n",
    "        train = lgb.Dataset(data, labels)\n",
    "                \n",
    "        #integer and string parameters, used with hp.choice()\n",
    "        boosting_list = [{'boosting': 'gbdt',\n",
    "                          'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                         {'boosting': 'goss',\n",
    "                          'subsample': 1.0,\n",
    "                         'top_rate': hp.uniform('top_rate', 0, 0.5),\n",
    "                         'other_rate': hp.uniform('other_rate', 0, 0.5)}] #if including 'dart', make sure to set 'n_estimators'\n",
    "        metric_list = ['MAE', 'RMSE'] \n",
    "        #for classification comment out the line above and uncomment the line below\n",
    "        #metric_list = ['auc'] #modify as required for other classification metrics\n",
    "        objective_list_reg = ['huber', 'gamma', 'fair', 'tweedie']\n",
    "        objective_list_class = ['binary', 'cross_entropy']\n",
    "        #for classification set objective_list = objective_list_class\n",
    "        objective_list = objective_list_reg\n",
    "\n",
    "        space ={'boosting' : hp.choice('boosting', boosting_list),\n",
    "                'num_leaves' : hp.quniform('num_leaves', 2, LGBM_MAX_LEAVES, 1),\n",
    "                'max_depth': hp.quniform('max_depth', 2, LGBM_MAX_DEPTH, 1),\n",
    "                'max_bin': hp.quniform('max_bin', 32, 255, 1),\n",
    "                'min_data_in_leaf': hp.quniform('min_data_in_leaf', 1, 256, 1),\n",
    "                'min_data_in_bin': hp.quniform('min_data_in_bin', 1, 256, 1),\n",
    "                'min_gain_to_split' : hp.quniform('min_gain_to_split', 0.1, 5, 0.01),\n",
    "                'lambda_l1' : hp.uniform('lambda_l1', 0, 5),\n",
    "                'lambda_l2' : hp.uniform('lambda_l2', 0, 5),\n",
    "                'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'metric' : hp.choice('metric', metric_list),\n",
    "                'objective' : hp.choice('objective', objective_list),\n",
    "                'feature_fraction' : hp.quniform('feature_fraction', 0.5, 1, 0.01),\n",
    "                'bagging_fraction' : hp.quniform('bagging_fraction', 0.5, 1, 0.01)\n",
    "            }\n",
    "        \n",
    "        #optional: activate GPU for LightGBM\n",
    "        #follow compilation steps here:\n",
    "        #https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm/\n",
    "        #then uncomment lines below:\n",
    "        #space['device'] = 'gpu'\n",
    "        #space['gpu_platform_id'] = 0,\n",
    "        #space['gpu_device_id'] =  0\n",
    "\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=num_evals, \n",
    "                    trials=trials)\n",
    "                \n",
    "        #fmin() will return the index of values chosen from the lists/arrays in 'space'\n",
    "        #to obtain actual values, index values are used to subset the original lists/arrays\n",
    "        best['boosting'] = boosting_list[best['boosting']]['boosting']#nested dict, index twice\n",
    "        best['metric'] = metric_list[best['metric']]\n",
    "        best['objective'] = objective_list[best['objective']]\n",
    "                \n",
    "        #cast floats of integer params to int\n",
    "        for param in integer_params:\n",
    "            best[param] = int(best[param])\n",
    "        \n",
    "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "        if diagnostic:\n",
    "            return(best, trials)\n",
    "        else:\n",
    "            return(best)\n",
    "    \n",
    "    #==========\n",
    "    #XGBoost\n",
    "    #==========\n",
    "    \n",
    "    if package=='xgb':\n",
    "        \n",
    "        print('Running {} rounds of XGBoost parameter optimisation:'.format(num_evals))\n",
    "        #clear space\n",
    "        gc.collect()\n",
    "        \n",
    "        integer_params = ['max_depth']\n",
    "        \n",
    "        def objective(space_params):\n",
    "            \n",
    "            for param in integer_params:\n",
    "                space_params[param] = int(space_params[param])\n",
    "                \n",
    "            #extract multiple nested tree_method conditional parameters\n",
    "            #libera te tutemet ex inferis\n",
    "            if space_params['tree_method']['tree_method'] == 'hist':\n",
    "                max_bin = space_params['tree_method'].get('max_bin')\n",
    "                space_params['max_bin'] = int(max_bin)\n",
    "                if space_params['tree_method']['grow_policy']['grow_policy']['grow_policy'] == 'depthwise':\n",
    "                    grow_policy = space_params['tree_method'].get('grow_policy').get('grow_policy').get('grow_policy')\n",
    "                    space_params['grow_policy'] = grow_policy\n",
    "                    space_params['tree_method'] = 'hist'\n",
    "                else:\n",
    "                    max_leaves = space_params['tree_method']['grow_policy']['grow_policy'].get('max_leaves')\n",
    "                    space_params['grow_policy'] = 'lossguide'\n",
    "                    space_params['max_leaves'] = int(max_leaves)\n",
    "                    space_params['tree_method'] = 'hist'\n",
    "            else:\n",
    "                space_params['tree_method'] = space_params['tree_method'].get('tree_method')\n",
    "                \n",
    "            #for classification replace EVAL_METRIC_XGB_REG with EVAL_METRIC_XGB_CLASS\n",
    "            cv_results = xgb.cv(space_params, train, nfold=N_FOLDS, metrics=[EVAL_METRIC_XGB_REG],\n",
    "                             early_stopping_rounds=100, stratified=False, seed=42)\n",
    "            \n",
    "            best_loss = cv_results['test-mae-mean'].iloc[-1] #or 'test-rmse-mean' if using RMSE\n",
    "            #for classification, comment out the line above and uncomment the line below:\n",
    "            #best_loss = 1 - cv_results['test-auc-mean'].iloc[-1]\n",
    "            #if necessary, replace 'test-auc-mean' with 'test-[your-preferred-metric]-mean'\n",
    "            return{'loss':best_loss, 'status': STATUS_OK }\n",
    "        \n",
    "        train = xgb.DMatrix(data, labels)\n",
    "        \n",
    "        #integer and string parameters, used with hp.choice()\n",
    "        boosting_list = ['gbtree', 'gblinear'] #if including 'dart', make sure to set 'n_estimators'\n",
    "        metric_list = ['MAE', 'RMSE'] \n",
    "        #for classification comment out the line above and uncomment the line below\n",
    "        #metric_list = ['auc']\n",
    "        #modify as required for other classification metrics classification\n",
    "        \n",
    "        tree_method = [{'tree_method' : 'exact'},\n",
    "               {'tree_method' : 'approx'},\n",
    "               {'tree_method' : 'hist',\n",
    "                'max_bin': hp.quniform('max_bin', 2**3, 2**7, 1),\n",
    "                'grow_policy' : {'grow_policy': {'grow_policy':'depthwise'},\n",
    "                                'grow_policy' : {'grow_policy':'lossguide',\n",
    "                                                  'max_leaves': hp.quniform('max_leaves', 32, XGB_MAX_LEAVES, 1)}}}]\n",
    "        \n",
    "        #if using GPU, replace 'exact' with 'gpu_exact' and 'hist' with\n",
    "        #'gpu_hist' in the nested dictionary above\n",
    "        \n",
    "        objective_list_reg = ['reg:squarederror', 'reg:gamma', 'reg:tweedie']\n",
    "        objective_list_class = ['reg:logistic', 'binary:logistic']\n",
    "        #for classification change line below to 'objective_list = objective_list_class'\n",
    "        objective_list = objective_list_reg\n",
    "        \n",
    "        space ={'boosting' : hp.choice('boosting', boosting_list),\n",
    "                'tree_method' : hp.choice('tree_method', tree_method),\n",
    "                'max_depth': hp.quniform('max_depth', 2, XGB_MAX_DEPTH, 1),\n",
    "                'reg_alpha' : hp.uniform('reg_alpha', 0, 5),\n",
    "                'reg_lambda' : hp.uniform('reg_lambda', 0, 5),\n",
    "                'min_child_weight' : hp.uniform('min_child_weight', 0, 5),\n",
    "                'gamma' : hp.uniform('gamma', 0, 5),\n",
    "                'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'eval_metric' : hp.choice('eval_metric', metric_list),\n",
    "                'objective' : hp.choice('objective', objective_list),\n",
    "                'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                'colsample_bynode' : hp.quniform('colsample_bynode', 0.1, 1, 0.01),\n",
    "                'colsample_bylevel' : hp.quniform('colsample_bylevel', 0.1, 1, 0.01),\n",
    "                'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                'nthread' : -1\n",
    "            }\n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=num_evals, \n",
    "                    trials=trials)\n",
    "        \n",
    "        best['tree_method'] = tree_method[best['tree_method']]['tree_method']\n",
    "        best['boosting'] = boosting_list[best['boosting']]\n",
    "        best['eval_metric'] = metric_list[best['eval_metric']]\n",
    "        best['objective'] = objective_list[best['objective']]\n",
    "        \n",
    "        #cast floats of integer params to int\n",
    "        for param in integer_params:\n",
    "            best[param] = int(best[param])\n",
    "        if 'max_leaves' in best:\n",
    "            best['max_leaves'] = int(best['max_leaves'])\n",
    "        if 'max_bin' in best:\n",
    "            best['max_bin'] = int(best['max_bin'])\n",
    "        \n",
    "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "        \n",
    "        if diagnostic:\n",
    "            return(best, trials)\n",
    "        else:\n",
    "            return(best)\n",
    "    \n",
    "    #==========\n",
    "    #CatBoost\n",
    "    #==========\n",
    "    \n",
    "    if package=='cb':\n",
    "        \n",
    "        print('Running {} rounds of CatBoost parameter optimisation:'.format(num_evals))\n",
    "        \n",
    "        #clear memory \n",
    "        gc.collect()\n",
    "            \n",
    "        integer_params = ['depth',\n",
    "                          #'one_hot_max_size', #for categorical data\n",
    "                          #'min_data_in_leaf',\n",
    "                          'max_bin']\n",
    "        \n",
    "        def objective(space_params):\n",
    "                        \n",
    "            #cast integer params from float to int\n",
    "            for param in integer_params:\n",
    "                space_params[param] = int(space_params[param])\n",
    "                \n",
    "            #extract nested conditional parameters\n",
    "            if space_params['bootstrap_type']['bootstrap_type'] == 'Bayesian':\n",
    "                bagging_temp = space_params['bootstrap_type'].get('bagging_temperature')\n",
    "                space_params['bagging_temperature'] = bagging_temp\n",
    "                \n",
    "#             if space_params['grow_policy']['grow_policy'] == 'LossGuide':\n",
    "#                 max_leaves = space_params['grow_policy'].get('max_leaves')\n",
    "#                 space_params['max_leaves'] = int(max_leaves)\n",
    "                \n",
    "            space_params['bootstrap_type'] = space_params['bootstrap_type']['bootstrap_type']\n",
    "#             space_params['grow_policy'] = space_params['grow_policy']['grow_policy']\n",
    "                           \n",
    "            #random_strength cannot be < 0\n",
    "            space_params['random_strength'] = max(space_params['random_strength'], 0)\n",
    "            #fold_len_multiplier cannot be < 1\n",
    "            space_params['fold_len_multiplier'] = max(space_params['fold_len_multiplier'], 1)\n",
    "                       \n",
    "            #for classification set stratified=True\n",
    "            cv_results = cb.cv(train, space_params, fold_count=N_FOLDS, \n",
    "                             early_stopping_rounds=25, stratified=False, partition_random_seed=42)\n",
    "           \n",
    "            best_loss = cv_results['test-MAE-mean'].iloc[-1] #'test-RMSE-mean' for RMSE\n",
    "            #for classification, comment out the line above and uncomment the line below:\n",
    "            #best_loss = cv_results['test-Logloss-mean'].iloc[-1]\n",
    "            #if necessary, replace 'test-Logloss-mean' with 'test-[your-preferred-metric]-mean'\n",
    "            \n",
    "            return{'loss':best_loss, 'status': STATUS_OK}\n",
    "        \n",
    "        train = cb.Pool(data, labels.astype('float32'))\n",
    "        \n",
    "        #integer and string parameters, used with hp.choice()\n",
    "        bootstrap_type = [  #{'bootstrap_type':'Poisson'}, \n",
    "                           {'bootstrap_type':'Bayesian',\n",
    "                            'bagging_temperature' : hp.loguniform('bagging_temperature', np.log(1), np.log(50))},\n",
    "                          {'bootstrap_type':'Bernoulli'}] \n",
    "        LEB = ['No', 'AnyImprovement'] #remove 'Armijo' if not using GPU\n",
    "        #score_function = ['Correlation', 'L2', 'NewtonCorrelation', 'NewtonL2']\n",
    "        grow_policy = [{'grow_policy':'SymmetricTree'},\n",
    "                       {'grow_policy':'Depthwise'},\n",
    "                       {'grow_policy':'Lossguide',\n",
    "                        'max_leaves': hp.quniform('max_leaves', 2, 32, 1)}]\n",
    "        eval_metric_list_reg = ['MAE', 'RMSE', 'Poisson']\n",
    "        eval_metric_list_class = ['Logloss', 'AUC', 'F1']\n",
    "        #for classification change line below to 'eval_metric_list = eval_metric_list_class'\n",
    "        eval_metric_list = eval_metric_list_reg\n",
    "                \n",
    "        space ={'depth': hp.quniform('depth', 2, CB_MAX_DEPTH, 1),\n",
    "                'max_bin' : hp.quniform('max_bin', 1, 32, 1), #if using CPU just set this to 254\n",
    "                'l2_leaf_reg' : hp.uniform('l2_leaf_reg', 0, 5),\n",
    "#                 'min_data_in_leaf' : hp.quniform('min_data_in_leaf', 1, 50, 1),\n",
    "                'random_strength' : hp.loguniform('random_strength', np.log(0.005), np.log(5)),\n",
    "                #'one_hot_max_size' : hp.quniform('one_hot_max_size', 2, 16, 1), #uncomment if using categorical features\n",
    "                'bootstrap_type' : hp.choice('bootstrap_type', bootstrap_type),\n",
    "                'learning_rate' : hp.uniform('learning_rate', 0.05, 0.25),\n",
    "                'eval_metric' : hp.choice('eval_metric', eval_metric_list),\n",
    "                'objective' : OBJECTIVE_CB_REG,\n",
    "                #'score_function' : hp.choice('score_function', score_function), #crashes kernel - reason unknown\n",
    "                'leaf_estimation_backtracking' : hp.choice('leaf_estimation_backtracking', LEB),\n",
    "                #'grow_policy': hp.choice('grow_policy', grow_policy),\n",
    "                #'colsample_bylevel' : hp.quniform('colsample_bylevel', 0.1, 1, 0.01),# CPU only\n",
    "                'fold_len_multiplier' : hp.loguniform('fold_len_multiplier', np.log(1.01), np.log(2.5)),\n",
    "                'od_type' : 'Iter',\n",
    "                'od_wait' : 25,\n",
    "                'task_type' : 'GPU',\n",
    "                'verbose' : 0\n",
    "            }\n",
    "        \n",
    "        #optional: run CatBoost without GPU\n",
    "        #uncomment line below\n",
    "        space['task_type'] = 'CPU'\n",
    "            \n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=num_evals, \n",
    "                    trials=trials)\n",
    "        \n",
    "        #unpack nested dicts first\n",
    "        best['bootstrap_type'] = bootstrap_type[best['bootstrap_type']]['bootstrap_type']\n",
    "        #best['grow_policy'] = grow_policy[best['grow_policy']]['grow_policy']\n",
    "        best['eval_metric'] = eval_metric_list[best['eval_metric']]\n",
    "        \n",
    "        #best['score_function'] = score_function[best['score_function']] \n",
    "        #best['leaf_estimation_method'] = LEM[best['leaf_estimation_method']] #CPU only\n",
    "        best['leaf_estimation_backtracking'] = LEB[best['leaf_estimation_backtracking']]        \n",
    "        \n",
    "        #cast floats of integer params to int\n",
    "        for param in integer_params:\n",
    "            best[param] = int(best[param])\n",
    "        if 'max_leaves' in best:\n",
    "            best['max_leaves'] = int(best['max_leaves'])\n",
    "        \n",
    "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "        \n",
    "        if diagnostic:\n",
    "            return(best, trials)\n",
    "        else:\n",
    "            return(best)\n",
    "    \n",
    "    else:\n",
    "        print('Package not recognised. Please use \"lgbm\" for LightGBM, \"xgb\" for XGBoost or \"cb\" for CatBoost.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 rounds of CatBoost parameter optimisation:\n",
      "100%|██████████| 50/50 [3:01:56<00:00, 103.28s/it, best loss: 2.0504313346532688]   \n",
      "{bootstrap_type: Bernoulli\n",
      "depth: 8\n",
      "eval_metric: RMSE\n",
      "fold_len_multiplier: 1.4665755301338386\n",
      "l2_leaf_reg: 3.1884879156314594\n",
      "leaf_estimation_backtracking: AnyImprovement\n",
      "learning_rate: 0.15692972872529823\n",
      "max_bin: 18\n",
      "random_strength: 0.005213763775616797}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap_type': 'Bernoulli',\n",
       " 'depth': 8,\n",
       " 'eval_metric': 'RMSE',\n",
       " 'fold_len_multiplier': 1.4665755301338386,\n",
       " 'l2_leaf_reg': 3.1884879156314594,\n",
       " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
       " 'learning_rate': 0.15692972872529823,\n",
       " 'max_bin': 18,\n",
       " 'random_strength': 0.005213763775616797}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_params = quick_hyperopt(X_train, y_train_label, 'cb', 50)\n",
    "cb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 rounds of XGBoost parameter optimisation:\n",
      "100%|██████████| 50/50 [03:39<00:00,  2.98s/it, best loss: 2.1859045999999998]\n",
      "{boosting: gblinear\n",
      "colsample_bylevel: 0.39\n",
      "colsample_bynode: 0.59\n",
      "colsample_bytree: 0.39\n",
      "eval_metric: MAE\n",
      "gamma: 4.966635414849523\n",
      "learning_rate: 0.1964494593361629\n",
      "max_bin: 71\n",
      "max_depth: 15\n",
      "max_leaves: 748\n",
      "min_child_weight: 1.6949682076025638\n",
      "objective: reg:squarederror\n",
      "reg_alpha: 0.0038501890468657374\n",
      "reg_lambda: 3.8197771229477286\n",
      "subsample: 1.0\n",
      "tree_method: hist}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gblinear',\n",
       " 'colsample_bylevel': 0.39,\n",
       " 'colsample_bynode': 0.59,\n",
       " 'colsample_bytree': 0.39,\n",
       " 'eval_metric': 'MAE',\n",
       " 'gamma': 4.966635414849523,\n",
       " 'learning_rate': 0.1964494593361629,\n",
       " 'max_bin': 71,\n",
       " 'max_depth': 15,\n",
       " 'max_leaves': 748,\n",
       " 'min_child_weight': 1.6949682076025638,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'reg_alpha': 0.0038501890468657374,\n",
       " 'reg_lambda': 3.8197771229477286,\n",
       " 'subsample': 1.0,\n",
       " 'tree_method': 'hist'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = quick_hyperopt(X_train, y_train_label, 'xgb', 50)\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 rounds of LightGBM parameter optimisation:\n",
      "100%|██████████| 50/50 [2:04:46<00:00, 221.58s/it, best loss: 2.031512810727373]  \n",
      "{bagging_fraction: 0.84\n",
      "boosting: gbdt\n",
      "feature_fraction: 0.89\n",
      "lambda_l1: 3.1182900937385454\n",
      "lambda_l2: 3.2470389978527785\n",
      "learning_rate: 0.045592800827466404\n",
      "max_bin: 241\n",
      "max_depth: 16\n",
      "metric: MAE\n",
      "min_data_in_bin: 38\n",
      "min_data_in_leaf: 3\n",
      "min_gain_to_split: 1.81\n",
      "num_leaves: 1813\n",
      "objective: fair\n",
      "subsample: 0.9998541677924023}\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = quick_hyperopt(X_train, y_train_label, 'lgbm', 50)\n",
    "lgbm_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
