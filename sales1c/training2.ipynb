{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file_name):\n",
    "    data_dir = '/Users/keiji/work/kaggle/sales1c/'\n",
    "    pickle = data_dir + file_name + '.pickle'\n",
    "    if os.path.exists(pickle):\n",
    "        return pd.read_pickle(pickle)\n",
    "    df = pd.read_csv(data_dir + file_name)\n",
    "    df.to_pickle(pickle)\n",
    "    return df\n",
    "\n",
    "df_icats = read('item_categories.csv')\n",
    "df_items = read('items.csv')\n",
    "df_shops = read('shops.csv')\n",
    "df_test = read('test.csv.gz')\n",
    "df_sales = read('sales_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers.\n",
    "# I'm not sure if this really matters.\n",
    "df_sales = df_sales[df_sales.item_price < 60000]\n",
    "df_sales = df_sales[df_sales.item_cnt_day < 700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['item_sales'] = df_sales.item_price * df_sales.item_cnt_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date_block_num</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id</th>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0   1   2   3   4\n",
       "date_block_num     0   0   0   0   0\n",
       "shop_id            0   0   0   0   0\n",
       "item_id           19  27  28  29  32\n",
       "item_category_id  40  19  30  23  40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_shop_id = df_sales[['date_block_num', 'shop_id']].drop_duplicates().reset_index(drop=True)\n",
    "unique_item_id = df_sales[['date_block_num', 'item_id']].drop_duplicates().reset_index(drop=True)\n",
    "df_train = (\n",
    "    pd.DataFrame({'date_block_num': np.arange(34)})\n",
    "    .merge(unique_shop_id, how='left', on='date_block_num')\n",
    "    .merge(unique_item_id, how='left', on='date_block_num')\n",
    "    .merge(df_items[['item_id', 'item_category_id']], how='left', on='item_id')\n",
    "    .sort_values(by=['date_block_num', 'shop_id', 'item_id'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df_sales.groupby(['date_block_num', 'shop_id', 'item_id'])\n",
    "    .agg({\n",
    "        'item_cnt_day': 'sum',\n",
    "        'item_price': 'median',\n",
    "        'item_sales': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_day': 'item_cnt_month',\n",
    "        'item_price': 'median_price',\n",
    "        'item_sales': 'item_sales_month',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'shop_id', 'item_id'])\n",
    "df_train.item_cnt_month.fillna(0.0, inplace=True)\n",
    "df_train.item_sales_month.fillna(0.0, inplace=True)\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df_train.groupby(['date_block_num', 'shop_id', 'item_category_id'])\n",
    "    .agg({\n",
    "        'item_cnt_month': 'sum',\n",
    "        'item_sales_month': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_month': 'icat_cnt_month',\n",
    "        'item_sales_month': 'icat_sales_month',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'shop_id', 'item_category_id'])\n",
    "df_train.icat_cnt_month.fillna(0.0, inplace=True)\n",
    "df_train.icat_sales_month.fillna(0.0, inplace=True)\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df_sales.groupby(['date_block_num', 'item_id'])\n",
    "    .agg({\n",
    "        'item_cnt_day': 'sum',\n",
    "        'item_price': 'median',\n",
    "        'item_sales': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_day': 'item_cnt_month_allshops',\n",
    "        'item_price': 'median_price_allshops',\n",
    "        'item_sales': 'item_sales_month_allshops',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'item_id'])\n",
    "df_train.median_price.fillna(df_train.median_price_allshops, inplace=True)\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df_train.groupby(['date_block_num', 'item_category_id'])\n",
    "    .agg({\n",
    "        'item_cnt_month_allshops': 'sum',\n",
    "        'item_sales_month_allshops': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_month_allshops': 'icat_cnt_month_allshops',\n",
    "        'item_sales_month_allshops': 'icat_sales_month_allshops',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'item_category_id'])\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in [['shop_id'], ['item_category_id'], ['shop_id', 'item_category_id']]:\n",
    "    print('processing:', cols)\n",
    "    df_agg = (\n",
    "        df_train.groupby(['date_block_num'] + cols)\n",
    "        .item_cnt_month\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'item_cnt_month': 'target_enc#' + ('|'.join(cols))})\n",
    "    )\n",
    "    df_train = df_train.merge(df_agg, how='left', on=['date_block_num']+cols)\n",
    "    \n",
    "    agecol = 'age#' + ('|'.join(cols))\n",
    "    df_agg = (\n",
    "        df_train.groupby(cols)\n",
    "        .date_block_num\n",
    "        .min()\n",
    "        .reset_index()\n",
    "        .rename(columns={'date_block_num': agecol})\n",
    "    )\n",
    "    df_train = df_train.merge(df_agg, how='left', on=cols)\n",
    "    df_train[agecol] = df_train.date_block_num - df_train[agecol]\n",
    "\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#df_train['price_delta'] = df_train.median_price - df_train.median_price_allshops\n",
    "#df_train['price_ratio'] = df_train.median_price / df_train.median_price_allshops\n",
    "df_train['item_cnt_ratio'] = sigmoid(df_train.item_cnt_month / df_train.item_cnt_month_allshops)\n",
    "df_train['item_cnt_ratio'].fillna(0.0, inplace=True)\n",
    "#df_train['item_sales_ratio'] = df_train.item_sales_month / df_train.item_sales_month_allshops\n",
    "#df_train['item_sales_ratio'].fillna(0.0, inplace=True)\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def rename_column(index, col_name):\n",
    "    if col_name in ['shop_id', 'item_id']:\n",
    "        return col_name\n",
    "    return '{}_{}'.format(col_name, index)\n",
    "    \n",
    "def make_features(label_block):\n",
    "    label_df = df_train.loc[df_train.date_block_num == label_block, ['shop_id', 'item_id', 'item_cnt_month']].reset_index(drop=True)\n",
    "    y = label_df.item_cnt_month#.map(lambda x: max(0, min(40, x)))\n",
    "    return make_features2(label_block, label_df), y\n",
    "\n",
    "def make_features2(label_block, label_df):\n",
    "    X = label_df[['shop_id', 'item_id']]\n",
    "    for i in [1,2,12,13]:\n",
    "        feature_block = label_block - i\n",
    "        dff = (\n",
    "            df_train.loc[df_train.date_block_num == feature_block]\n",
    "            .drop(['date_block_num', 'item_category_id'], axis=1)\n",
    "            .rename(partial(rename_column, i), axis='columns')\n",
    "        )\n",
    "        X = X.merge(dff, how='left', on=['shop_id', 'item_id'])\n",
    "\n",
    "    delta_features = ['item_cnt_month', 'item_cnt_month_allshops',\n",
    "                      'item_sales_month', 'item_sales_month_allshops',\n",
    "                      'icat_cnt_month', 'icat_cnt_month_allshops',\n",
    "                      'icat_sales_month', 'icat_sales_month_allshops']\n",
    "    for prefix in delta_features:\n",
    "        for i in [1, 12]:\n",
    "            X['{}_DELTA{}'.format(prefix, i)] = X['{}_{}'.format(prefix,i)] - X['{}_{}'.format(prefix,i+1)]\n",
    "\n",
    "    columns_to_drop = (\n",
    "        ['shop_id', 'item_id']\n",
    "        + [col for col in X.columns\n",
    "           if any([col.endswith('_{}'.format(i)) for i in [2,12,13]])])\n",
    "    X.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    X.fillna(0, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <33: VALIDATION,TUNING\n",
    "# =33: FINAL VALIDATION\n",
    "# =34: TEST\n",
    "PREDICTION_BLOCK = 32\n",
    "TRAINING_BLOCK_RANGE = range(14, PREDICTION_BLOCK)\n",
    "\n",
    "def is_tuning():\n",
    "    return PREDICTION_BLOCK < 33\n",
    "def is_validation():\n",
    "    return PREDICTION_BLOCK < 34\n",
    "def is_test():\n",
    "    return PREDICTION_BLOCK == 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "for label_block in TRAINING_BLOCK_RANGE:\n",
    "    X, y = make_features(label_block)\n",
    "    Xs.append(X)\n",
    "    ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(Xs, sort=False)\n",
    "y_train = pd.concat(ys, sort=False)\n",
    "X_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_validation():\n",
    "    X_val, y_val = make_features(PREDICTION_BLOCK)\n",
    "    X_combined = pd.concat([X_train, X_val], sort=False)\n",
    "else:\n",
    "    X_test = make_features2(PREDICTION_BLOCK, df_test)\n",
    "    X_combined = pd.concat([X_train, X_test], sort=False)\n",
    "\n",
    "scaler = StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_combined.values)\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_combined.values)\n",
    "\n",
    "def transform(X):\n",
    "    pca_features = pca.transform(X.values)\n",
    "    X['pca0'] = pca_features[:,0]\n",
    "    X['pca1'] = pca_features[:,1]\n",
    "    X['pca2'] = pca_features[:,2]\n",
    "\n",
    "transform(X_train)\n",
    "if is_validation():\n",
    "    transform(X_val)\n",
    "else:\n",
    "    transform(X_test)\n",
    "\n",
    "X_train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'num_leaves': 90, 'reg_lambda': 13.220339591026585, 'reg_alpha': 29.630695197981943, 'min_data_in_leaf': 12,\n",
    "        'colsample_bytree': 0.9555622996470243, 'learning_rate': 0.059291081728894066, 'max_depth': 8, 'subsample': 0.910633831712105}\n",
    "\n",
    "reg = LGBMRegressor(\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    n_estimators=400,\n",
    "    **params,\n",
    ")\n",
    "\n",
    "if is_validation():\n",
    "    reg.fit(X_train, y_train, eval_metric='mse', early_stopping_rounds=200, eval_set=[(X_val, y_val)], verbose=True)\n",
    "else:\n",
    "    reg.fit(X_train, y_train, eval_metric='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': reg.feature_importances_})\n",
    "feature_importances.sort_values(by='importance', ascending=True, inplace=True)\n",
    "feature_importances.plot(x='feature', y='importance', kind='barh', sort_columns=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(s):\n",
    "    return s.map(lambda x: max(0.0, min(20.0, x)))\n",
    "\n",
    "def rmse(x, y):\n",
    "    return math.sqrt(mean_squared_error(clip(x), clip(y)))\n",
    "\n",
    "if is_validation():\n",
    "    y_pred = pd.Series(reg.predict(X_val))\n",
    "    print('validation RMSE score:', rmse(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pd.Series(reg.predict(X_train))\n",
    "print('training RMSE score', rmse(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "min_rmse = 10\n",
    "def objective(params):\n",
    "    global min_rmse\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "    \n",
    "    model = LGBMRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    \n",
    "    model.fit(X_train, y_train, early_stopping_rounds=200, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    y_pred = pd.Series(model.predict(X_val))\n",
    "    score = rmse(y_val, y_pred)\n",
    "    if score < min_rmse:\n",
    "        min_rmse = score\n",
    "        print(\"RMSE {:.6f}: params={}\".format(score, params))\n",
    "    return -score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hyperopt.hp.quniform('num_leaves', 50, 200, 10),\n",
    "    'max_depth': hyperopt.hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_data_in_leaf': hyperopt.hp.quniform('min_data_in_leaf',  5, 25, 2),\n",
    "    'colsample_bytree': hyperopt.hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 0.03, 0.9),\n",
    "    'subsample': hyperopt.hp.uniform('subsample', 0.5, 1.0),\n",
    "    'reg_lambda': hyperopt.hp.uniform('reg_lambda', 0.0, 50.0),\n",
    "}\n",
    "\n",
    "if is_tuning():\n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=hyperopt.tpe.suggest,\n",
    "        max_evals=1000)\n",
    "    best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_test():\n",
    "    y_test_pred = clip(pd.Series(reg.predict(X_test)))\n",
    "    y_test_pred_df = pd.DataFrame(y_test_pred)\n",
    "    y_test_pred_df.info()\n",
    "    y_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_submit = pd.DataFrame(df_test.loc[:,'ID'])\n",
    "    df_submit['item_cnt_month'] = y_test_pred\n",
    "    df_submit.to_csv('lgbm_tuned4.csv', index=False)\n",
    "    df_submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
