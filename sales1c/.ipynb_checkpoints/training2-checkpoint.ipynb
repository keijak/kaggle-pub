{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file_name):\n",
    "    data_dir = '/Users/keiji/work/kaggle/sales1c/'\n",
    "    pickle = data_dir + file_name + '.pickle'\n",
    "    if os.path.exists(pickle):\n",
    "        return pd.read_pickle(pickle)\n",
    "    df = pd.read_csv(data_dir + file_name)\n",
    "    df.to_pickle(pickle)\n",
    "    return df\n",
    "\n",
    "df_icats = read('item_categories.csv')\n",
    "df_items = read('items.csv')\n",
    "df_shops = read('shops.csv')\n",
    "df_test = read('test.csv.gz')\n",
    "df_sales = read('sales_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers.\n",
    "# I'm not sure if this really matters.\n",
    "df_sales = df_sales[df_sales.item_price < 60000]\n",
    "df_sales = df_sales[df_sales.item_cnt_day < 700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['item_sales'] = df_sales.item_price * df_sales.item_cnt_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_shop_id = df_sales[['date_block_num', 'shop_id']].drop_duplicates().reset_index(drop=True)\n",
    "unique_item_id = df_sales[['date_block_num', 'item_id']].drop_duplicates().reset_index(drop=True)\n",
    "df_train = (\n",
    "    pd.DataFrame({'date_block_num': np.arange(34)})\n",
    "    .merge(unique_shop_id, how='left', on='date_block_num')\n",
    "    .merge(unique_item_id, how='left', on='date_block_num')\n",
    "    .merge(df_items[['item_id', 'item_category_id']], how='left', on='item_id')\n",
    "    .sort_values(by=['date_block_num', 'shop_id', 'item_id'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_agg = (\n",
    "    df_sales.groupby(['date_block_num', 'shop_id', 'item_id'])\n",
    "    .agg({\n",
    "        'item_cnt_day': 'sum',\n",
    "        'item_price': 'median',\n",
    "        'item_sales': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_day': 'item_cnt_month',\n",
    "        'item_price': 'median_price',\n",
    "        'item_sales': 'item_sales_month',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'shop_id', 'item_id'])\n",
    "df_train.item_cnt_month.fillna(0.0, inplace=True)\n",
    "df_train.item_sales_month.fillna(0.0, inplace=True)\n",
    "\n",
    "df_agg = (\n",
    "    df_sales.groupby(['date_block_num', 'item_id'])\n",
    "    .agg({\n",
    "        'item_cnt_day': 'sum',\n",
    "        'item_price': 'median',\n",
    "        'item_sales': 'sum',\n",
    "    })\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'item_cnt_day': 'item_cnt_month_allshops',\n",
    "        'item_price': 'median_price_allshops',\n",
    "        'item_sales': 'item_sales_month_allshops',\n",
    "    })\n",
    ")\n",
    "df_train = df_train.merge(df_agg, how='left', on=['date_block_num', 'item_id'])\n",
    "df_train.median_price.fillna(df_train.median_price_allshops, inplace=True)\n",
    "\n",
    "for col in ['shop_id', 'item_id', 'item_category_id']:\n",
    "    df_agg = (\n",
    "        df_train.groupby(['date_block_num', col])\n",
    "        .item_cnt_month\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'item_cnt_month': 'meanenc_' + col})\n",
    "    )\n",
    "    df_train = df_train.merge(df_agg, how='left', on=['date_block_num', col])\n",
    "\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['price_delta'] = df_train.median_price - df_train.median_price_allshops\n",
    "#df_train['price_ratio'] = df_train.median_price / df_train.median_price_allshops\n",
    "df_train['item_cnt_ratio'] = df_train.item_cnt_month / df_train.item_cnt_month_allshops\n",
    "df_train['item_cnt_ratio'].fillna(0.0, inplace=True)\n",
    "#df_train['item_sales_ratio'] = df_train.item_sales_month / df_train.item_sales_month_allshops\n",
    "#df_train['item_sales_ratio'].fillna(0.0, inplace=True)\n",
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def rename_column(index, col_name):\n",
    "    if col_name in ['shop_id', 'item_id']:\n",
    "        return col_name\n",
    "    return '{}_{}'.format(col_name, index)\n",
    "    \n",
    "def make_features(label_block):\n",
    "    label_df = df_train.loc[df_train.date_block_num == label_block, ['shop_id', 'item_id', 'item_cnt_month']].reset_index(drop=True)\n",
    "    y = label_df.item_cnt_month#.map(lambda x: max(0, min(40, x)))\n",
    "    return make_features2(label_block, label_df), y\n",
    "\n",
    "def make_features2(label_block, label_df):\n",
    "    X = label_df[['shop_id', 'item_id']]\n",
    "    # Only 1 month ago and 2 months ago\n",
    "    for i in range(1, 3):\n",
    "        feature_block = label_block - i\n",
    "        dff = (\n",
    "            df_train.loc[df_train.date_block_num == feature_block]\n",
    "            .drop(['date_block_num', 'item_category_id'], axis=1)\n",
    "            .rename(partial(rename_column, i), axis='columns')\n",
    "        )\n",
    "        X = X.merge(dff, how='left', on=['shop_id', 'item_id'])\n",
    "    X['item_cnt_month_delta'] = X['item_cnt_month_1'] - X['item_cnt_month_2']\n",
    "    X['item_cnt_month_allshops_delta'] = X['item_cnt_month_allshops_1'] - X['item_cnt_month_allshops_2']\n",
    "    X.drop(['shop_id', 'item_id'], axis=1, inplace=True)\n",
    "    X.fillna(0.0, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_BLOCK = 34\n",
    "TRAINING_BLOCK_RANGE = range(0, VALIDATION_BLOCK)\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "for label_block in TRAINING_BLOCK_RANGE:\n",
    "    X, y = make_features(label_block)\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n",
    "\n",
    "X_train = pd.concat(Xs)\n",
    "y_train = pd.concat(ys)\n",
    "X_train.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LGBMRegressor()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(s):\n",
    "    return s.map(lambda x: max(0.0, min(20.0, x)))\n",
    "\n",
    "def rmse(x, y):\n",
    "    return math.sqrt(mean_squared_error(clip(x), clip(y)))\n",
    "\n",
    "if VALIDATION_BLOCK < 34:\n",
    "    X_val, y_val = make_features(VALIDATION_BLOCK)\n",
    "    y_pred = pd.Series(reg.predict(X_val))\n",
    "    rmse(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = pd.Series(reg.predict(X_train))\n",
    "rmse(y_train, y_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': reg.feature_importances_})\n",
    "feature_importances.sort_values(by='importance', ascending=True, inplace=True)\n",
    "feature_importances.plot(x='feature', y='importance', kind='barh', sort_columns=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VALIDATION_BLOCK == 34:\n",
    "    X_test = make_features2(VALIDATION_BLOCK, df_test)\n",
    "    y_test_pred = clip(pd.Series(reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_pred).info()\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(df_test.loc[:,'ID'])\n",
    "df_submit['item_cnt_month'] = y_test_pred\n",
    "df_submit.to_csv('lgbm3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
